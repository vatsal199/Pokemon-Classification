{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xxAFGAbJWOJ2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import shutil# **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('/kaggle/input/stanford-dogs-dataset/images/Images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mJ35vyVIpg-G"
   },
   "outputs": [],
   "source": [
    "basePath = '/kaggle/'\n",
    "\n",
    "modelSave = basePath+'working/weights.pth'\n",
    "data_dir = basePath+'input/stanford-dogs-dataset/images/Images/'\n",
    "working_dir = basePath+'working/'\n",
    "model_file = '/kaggle/input/alexnet/alexnet.pth'\n",
    "\n",
    "num_classes = 120\n",
    "batch_size = 8\n",
    "num_epochs = 50\n",
    "input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Oroq2d4A6r9p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "c780N2trIg24"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs,labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iOOF8_V1InXs"
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(num_classes):\n",
    "    alexnet = models.alexnet(pretrained=True)\n",
    "    set_parameter_requires_grad(alexnet)\n",
    "    num_ftrs = alexnet.classifier[6].in_features\n",
    "\n",
    "    alexnet.classifier[6] = nn.Linear(num_ftrs,1024)\n",
    "    model = nn.Sequential( alexnet,nn.Linear(1024,num_classes), nn.Softmax(dim = 1))\n",
    "#     alexnet.classifier[6] = nn.Linear(num_ftrs,2048)\n",
    "#     model = nn.Sequential( alexnet,\n",
    "#                           nn.ReLU(),\n",
    "#                           nn.BatchNorm1d(2048),\n",
    "#                           nn.Linear(2048,1024),\n",
    "#                           nn.ReLU(),\n",
    "#                           nn.BatchNorm1d(1024),\n",
    "#                           nn.Linear(1024,num_classes), \n",
    "#                           nn.Softmax(dim = 1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HWMDvQw-SLmI"
   },
   "outputs": [],
   "source": [
    "# def initialize_model(num_classes):\n",
    "#     alexnet = models.alexnet(pretrained=True)\n",
    "#     set_parameter_requires_grad(alexnet)\n",
    "#     num_ftrs = alexnet.classifier[6].in_features   \n",
    "\n",
    "#     alexnet.classifier[6] = nn.Linear(num_ftrs,4096)\n",
    "#     model = nn.Sequential( alexnet,\n",
    "#                           nn.ReLU(),\n",
    "#                           nn.BatchNorm1d(4096),\n",
    "#                           nn.Linear(4096,1024),\n",
    "#                           nn.ReLU(),\n",
    "#                           nn.BatchNorm1d(1024),\n",
    "#                           nn.Linear(1024,num_classes), \n",
    "#                           nn.Softmax(dim = 1))\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ekvly_gT6WWp"
   },
   "outputs": [],
   "source": [
    "def getTrainDataLoaders():\n",
    "    # Data augmentation and normalization for training\n",
    "    # Just normalization for validation\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(input_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "    # Create training and validation datasets\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(working_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "    # Create training and validation dataloaders\n",
    "    dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "    return dataloaders_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SNhuHlIf7C3D"
   },
   "outputs": [],
   "source": [
    "def getUpdatablePara(model):\n",
    "    params_to_update = model.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if  param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "    return params_to_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_data(test_size = 0.75):\n",
    "    for dog_class in os.listdir(data_dir):\n",
    "        print(dog_class)\n",
    "        class_path = os.path.join(data_dir, dog_class)\n",
    "        img_name_list = os.listdir(class_path)\n",
    "        train_list = img_name_list[:int(test_size * len(img_name_list))]\n",
    "        val_list = img_name_list[int(test_size * len(img_name_list)):]\n",
    "        \n",
    "        destination_folder = os.path.join(working_dir, 'train', dog_class)\n",
    "        os.makedirs(destination_folder)            \n",
    "        for img in train_list:\n",
    "            source = os.path.join(class_path, img)\n",
    "            destination = os.path.join(destination_folder, img)\n",
    "            dest = shutil.copyfile(source, destination) \n",
    "        \n",
    "        destination_folder = os.path.join(working_dir, 'val', dog_class)\n",
    "        os.makedirs(destination_folder)\n",
    "        for img in val_list:\n",
    "            source = os.path.join(class_path, img)            \n",
    "            destination = os.path.join(destination_folder, img)\n",
    "            dest = shutil.copyfile(source, destination) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_model_to_cache():\n",
    "    cache_dir = os.path.expanduser(os.path.join('~', '.torch'))\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir)\n",
    "    models_dir = os.path.join(cache_dir, 'models')\n",
    "    if not os.path.exists(models_dir):\n",
    "        os.makedirs(models_dir)\n",
    "    \n",
    "    dest = shutil.copyfile(model_file, os.path.join(models_dir, os.path.basename(model_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Prepare Train and Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n02109961-Eskimo_dog\n",
      "n02094258-Norwich_terrier\n",
      "n02090721-Irish_wolfhound\n",
      "n02108089-boxer\n",
      "n02096437-Dandie_Dinmont\n",
      "n02106382-Bouvier_des_Flandres\n",
      "n02102480-Sussex_spaniel\n",
      "n02089078-black-and-tan_coonhound\n",
      "n02107312-miniature_pinscher\n",
      "n02085620-Chihuahua\n",
      "n02110185-Siberian_husky\n",
      "n02093428-American_Staffordshire_terrier\n",
      "n02111277-Newfoundland\n",
      "n02098413-Lhasa\n",
      "n02115913-dhole\n",
      "n02095570-Lakeland_terrier\n",
      "n02100735-English_setter\n",
      "n02116738-African_hunting_dog\n",
      "n02106166-Border_collie\n",
      "n02093991-Irish_terrier\n",
      "n02097658-silky_terrier\n",
      "n02091635-otterhound\n",
      "n02091831-Saluki\n",
      "n02110063-malamute\n",
      "n02112706-Brabancon_griffon\n",
      "n02110627-affenpinscher\n",
      "n02112137-chow\n",
      "n02105056-groenendael\n",
      "n02092339-Weimaraner\n",
      "n02090622-borzoi\n",
      "n02089973-English_foxhound\n",
      "n02099712-Labrador_retriever\n",
      "n02107574-Greater_Swiss_Mountain_dog\n",
      "n02113186-Cardigan\n",
      "n02105251-briard\n",
      "n02093859-Kerry_blue_terrier\n",
      "n02097209-standard_schnauzer\n",
      "n02092002-Scottish_deerhound\n",
      "n02087394-Rhodesian_ridgeback\n",
      "n02088466-bloodhound\n",
      "n02088632-bluetick\n",
      "n02102177-Welsh_springer_spaniel\n",
      "n02111129-Leonberg\n",
      "n02110958-pug\n",
      "n02086079-Pekinese\n",
      "n02107908-Appenzeller\n",
      "n02099429-curly-coated_retriever\n",
      "n02105505-komondor\n",
      "n02106030-collie\n",
      "n02101556-clumber\n",
      "n02096585-Boston_bull\n",
      "n02113712-miniature_poodle\n",
      "n02099267-flat-coated_retriever\n",
      "n02108000-EntleBucher\n",
      "n02110806-basenji\n",
      "n02097298-Scotch_terrier\n",
      "n02105412-kelpie\n",
      "n02088364-beagle\n",
      "n02091467-Norwegian_elkhound\n",
      "n02090379-redbone\n",
      "n02104365-schipperke\n",
      "n02088094-Afghan_hound\n",
      "n02099849-Chesapeake_Bay_retriever\n",
      "n02112350-keeshond\n",
      "n02106550-Rottweiler\n",
      "n02094114-Norfolk_terrier\n",
      "n02115641-dingo\n",
      "n02097474-Tibetan_terrier\n",
      "n02102973-Irish_water_spaniel\n",
      "n02102040-English_springer\n",
      "n02085936-Maltese_dog\n",
      "n02102318-cocker_spaniel\n",
      "n02091032-Italian_greyhound\n",
      "n02086646-Blenheim_spaniel\n",
      "n02101006-Gordon_setter\n",
      "n02099601-golden_retriever\n",
      "n02096177-cairn\n",
      "n02105855-Shetland_sheepdog\n",
      "n02097047-miniature_schnauzer\n",
      "n02096051-Airedale\n",
      "n02098105-soft-coated_wheaten_terrier\n",
      "n02086910-papillon\n",
      "n02101388-Brittany_spaniel\n",
      "n02091134-whippet\n",
      "n02085782-Japanese_spaniel\n",
      "n02113023-Pembroke\n",
      "n02109047-Great_Dane\n",
      "n02089867-Walker_hound\n",
      "n02108915-French_bulldog\n",
      "n02095314-wire-haired_fox_terrier\n",
      "n02100583-vizsla\n",
      "n02113799-standard_poodle\n",
      "n02100877-Irish_setter\n",
      "n02096294-Australian_terrier\n",
      "n02107683-Bernese_mountain_dog\n",
      "n02086240-Shih-Tzu\n",
      "n02093647-Bedlington_terrier\n",
      "n02093256-Staffordshire_bullterrier\n",
      "n02105162-malinois\n",
      "n02098286-West_Highland_white_terrier\n",
      "n02087046-toy_terrier\n",
      "n02108422-bull_mastiff\n",
      "n02106662-German_shepherd\n",
      "n02113978-Mexican_hairless\n",
      "n02109525-Saint_Bernard\n",
      "n02100236-German_short-haired_pointer\n",
      "n02111500-Great_Pyrenees\n",
      "n02094433-Yorkshire_terrier\n",
      "n02112018-Pomeranian\n",
      "n02095889-Sealyham_terrier\n",
      "n02105641-Old_English_sheepdog\n",
      "n02113624-toy_poodle\n",
      "n02088238-basset\n",
      "n02097130-giant_schnauzer\n",
      "n02111889-Samoyed\n",
      "n02107142-Doberman\n",
      "n02093754-Border_terrier\n",
      "n02108551-Tibetan_mastiff\n",
      "n02091244-Ibizan_hound\n",
      "n02104029-kuvasz\n"
     ]
    }
   ],
   "source": [
    "split_train_test_data(0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwYabkKX7oR_"
   },
   "source": [
    "# **Training and Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iWWsdyCJJFxE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000189b2191c4fe8a715e05c1f9139f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alexnet = initialize_model(num_classes)\n",
    "alexnet = alexnet.to(device)\n",
    "#print(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "97r-6fJpJB7x",
    "outputId": "3a17e844-1039-4952-91e7-0ef2062e300f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "dataloaders = getTrainDataLoaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JwUX-7c4IupU",
    "outputId": "8d72de6f-a28a-4121-bad8-10e389652546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t 0.classifier.6.weight\n",
      "\t 0.classifier.6.bias\n",
      "\t 1.weight\n",
      "\t 1.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = getUpdatablePara(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gtz6hjnpU_IY",
    "outputId": "84be97ad-7fcd-4f91-fce5-5522da6f1682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 4.7790 Acc: 0.0329\n",
      "val Loss: 4.7419 Acc: 0.0702\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 4.7137 Acc: 0.1041\n",
      "val Loss: 4.6570 Acc: 0.1574\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 4.6699 Acc: 0.1457\n",
      "val Loss: 4.6339 Acc: 0.1749\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 4.6533 Acc: 0.1584\n",
      "val Loss: 4.6260 Acc: 0.1824\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 4.6489 Acc: 0.1604\n",
      "val Loss: 4.6252 Acc: 0.1804\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 4.6451 Acc: 0.1626\n",
      "val Loss: 4.6230 Acc: 0.1824\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 4.6446 Acc: 0.1635\n",
      "val Loss: 4.6217 Acc: 0.1814\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 4.6418 Acc: 0.1644\n",
      "val Loss: 4.6215 Acc: 0.1824\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 4.6396 Acc: 0.1662\n",
      "val Loss: 4.6212 Acc: 0.1826\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 4.6398 Acc: 0.1661\n",
      "val Loss: 4.6200 Acc: 0.1836\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 4.6394 Acc: 0.1656\n",
      "val Loss: 4.6211 Acc: 0.1838\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 4.6373 Acc: 0.1692\n",
      "val Loss: 4.6198 Acc: 0.1819\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 4.6357 Acc: 0.1693\n",
      "val Loss: 4.6204 Acc: 0.1824\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 4.6351 Acc: 0.1699\n",
      "val Loss: 4.6198 Acc: 0.1819\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 4.6369 Acc: 0.1676\n",
      "val Loss: 4.6190 Acc: 0.1838\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 4.6335 Acc: 0.1708\n",
      "val Loss: 4.6192 Acc: 0.1819\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 4.6359 Acc: 0.1687\n",
      "val Loss: 4.6187 Acc: 0.1833\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 4.6346 Acc: 0.1696\n",
      "val Loss: 4.6167 Acc: 0.1855\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 4.6314 Acc: 0.1729\n",
      "val Loss: 4.6148 Acc: 0.1879\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 4.6294 Acc: 0.1745\n",
      "val Loss: 4.6148 Acc: 0.1886\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 4.6296 Acc: 0.1749\n",
      "val Loss: 4.6130 Acc: 0.1891\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 4.6285 Acc: 0.1764\n",
      "val Loss: 4.6133 Acc: 0.1884\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 4.6280 Acc: 0.1759\n",
      "val Loss: 4.6132 Acc: 0.1896\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 4.6274 Acc: 0.1763\n",
      "val Loss: 4.6131 Acc: 0.1901\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 4.6283 Acc: 0.1754\n",
      "val Loss: 4.6130 Acc: 0.1889\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 4.6261 Acc: 0.1778\n",
      "val Loss: 4.6133 Acc: 0.1886\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 4.6236 Acc: 0.1803\n",
      "val Loss: 4.6065 Acc: 0.1956\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 4.6185 Acc: 0.1858\n",
      "val Loss: 4.6059 Acc: 0.1958\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 4.6206 Acc: 0.1837\n",
      "val Loss: 4.6051 Acc: 0.1975\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 4.6203 Acc: 0.1835\n",
      "val Loss: 4.6053 Acc: 0.1973\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 4.6180 Acc: 0.1864\n",
      "val Loss: 4.6052 Acc: 0.1965\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 4.6196 Acc: 0.1843\n",
      "val Loss: 4.6052 Acc: 0.1968\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 4.6216 Acc: 0.1812\n",
      "val Loss: 4.6038 Acc: 0.1987\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 4.6161 Acc: 0.1877\n",
      "val Loss: 4.6049 Acc: 0.1987\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 4.6182 Acc: 0.1862\n",
      "val Loss: 4.6042 Acc: 0.1973\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 4.6175 Acc: 0.1869\n",
      "val Loss: 4.6042 Acc: 0.1987\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 4.6181 Acc: 0.1855\n",
      "val Loss: 4.6038 Acc: 0.1989\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 4.6179 Acc: 0.1852\n",
      "val Loss: 4.6042 Acc: 0.1980\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 4.6158 Acc: 0.1884\n",
      "val Loss: 4.6043 Acc: 0.1980\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 4.6159 Acc: 0.1879\n",
      "val Loss: 4.6037 Acc: 0.2001\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 4.6171 Acc: 0.1861\n",
      "val Loss: 4.6032 Acc: 0.1994\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 4.6150 Acc: 0.1882\n",
      "val Loss: 4.6033 Acc: 0.1985\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 4.6177 Acc: 0.1866\n",
      "val Loss: 4.6052 Acc: 0.1963\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 4.6169 Acc: 0.1859\n",
      "val Loss: 4.6039 Acc: 0.1980\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 4.6154 Acc: 0.1870\n",
      "val Loss: 4.6029 Acc: 0.1994\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 4.6163 Acc: 0.1872\n",
      "val Loss: 4.6032 Acc: 0.1989\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 4.6156 Acc: 0.1875\n",
      "val Loss: 4.6029 Acc: 0.1994\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 4.6166 Acc: 0.1861\n",
      "val Loss: 4.6046 Acc: 0.1968\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 4.6173 Acc: 0.1859\n",
      "val Loss: 4.6030 Acc: 0.1997\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 4.6137 Acc: 0.1900\n",
      "val Loss: 4.6025 Acc: 0.1994\n",
      "\n",
      "Training complete in 85m 3s\n",
      "Best val Acc: 0.200144\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "# optimizer_ft = optim.Adam(params_to_update, lr=0.001)\n",
    "\n",
    "#loss function \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "alexnet, hist = train_model(alexnet, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs)\n",
    "\n",
    "torch.save(alexnet.state_dict(), modelSave)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
